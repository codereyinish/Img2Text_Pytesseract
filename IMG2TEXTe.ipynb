{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgzmJL6LoGLTtOqnM4c631"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### git setup"],"metadata":{"id":"qPEMCS8waL6s"}},{"cell_type":"markdown","source":["#### start version control of all the files and put the files inside the drive , bcoz temporary colab session can delete this file"],"metadata":{"id":"7z_1H6JeciFU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"mmXMM50kY9kL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/Github/IMG2TEXTe\n"],"metadata":{"id":"r-hhcKHIZxJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/IMG2TEXTe.ipynb\" /content/drive/MyDrive/Github/IMG2TEXTe/\n"],"metadata":{"id":"QKjY-2EdZhtU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd drive/MyDrive/Github/IMG2TEXTe/"],"metadata":{"id":"3pY7N_b3Y1Ep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git init"],"metadata":{"id":"TOjAD477ZVgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Requirements.txt file\n","Google colab has most of the dependencies already installed(for instance, we dont need to install pandas , tensorflow or a pyhton ) so this req.txt file only contains dependencies which have to be explicitly installed"],"metadata":{"id":"y6UHga9fUf1f"}},{"cell_type":"code","source":["%%writefile requirements.txt\n","pytesseract==0.3.13\n","streamlit==1.38.0\n","pillow_heif==0.18.0\n","pyngrok==7.2.0\n","\n"],"metadata":{"id":"7vwM8_duUfQ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### installing system level software --> tesseract-ocr  with sudo apt -get"],"metadata":{"id":"WC7gfZd4b7al"}},{"cell_type":"code","source":["!pip install -r requirements.txt -q"],"metadata":{"id":"IOaaDE_SaWPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sudo apt-get install tesseract-ocr -q"],"metadata":{"id":"uzI7ot5ab6Rx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### checking installation"],"metadata":{"id":"0JlBx20Tavuw"}},{"cell_type":"code","source":["import pytesseract\n","print(pytesseract.get_tesseract_version())"],"metadata":{"id":"1ACU0N3Bauz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#addding tesseract to the path\n","pytesseract.pytesseract.tesseract_cmd = \"/bin/tesseract\""],"metadata":{"id":"7EJ1rjRvbUV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!which tesseract"],"metadata":{"id":"7B0_So8NbkEp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Image_processing File"],"metadata":{"id":"Gc6I4PCyaQm4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgwOb54nTIVY"},"outputs":[],"source":["%%writefile image_processing.py\n","import cv2\n","import pytesseract\n","# import asyncio\n","def getTextFromImage(img):\n","  grayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  ret, thresh1 = cv2.threshold(grayImg, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n","  rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25,25))\n","  contours, heirarchy = cv2.findContours(thresh1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE )\n","  grayImg2 = grayImg.copy()\n","  cnt_list = [] #stores output text and its position co-ordinate(x,y)\n","  for cnt in contours:\n","    x, y, w, h = cv2.boundingRect(cnt)\n","\n","  #Drawing the fixed definite Rectangle Boundary around the irregular shaped contour\n","  rect = cv2.rectangle(grayImg2,(x,y), (x+w, y+h), (0,255,0),2)\n","  #Drawing the circle to mark the start of the text region\n","  cv2.circle(grayImg2,(x,y), 8, (255,255,0), 8)\n","  #do 2D Numpy slicing to only get the detected text region, that means to slice out the rectangle boundary by using its boundary co-ordinates\n","  croppedImgRegions = grayImg2[y:y+h, x:x+w]\n","  #Now apply OCR on the cropped image\n","  text = pytesseract.image_to_string(croppedImgRegions)\n","  cnt_list.append([x,y, text])\n","  #this function sorts the text block from top to bottom(stick with y for now, x later if needed)\n","  sorted_list = sorted(cnt_list, key = lambda x: x[1])\n","  file = open(\"scanned_textfile\", \"w+\")\n","  file.write(\"\")\n","  file.close()\n","\n","  for(x,y,text) in sorted_list:\n","    file = open(\"scanned_textfile\", \"w\")\n","    #appending the text\n","    file.write(text)\n","    file.write(\"\\n\")\n","    file.close()\n","  with open(\"scanned_textfile\", \"r\") as f:\n","    textContent = f.read()\n","    return textContent\n","\n"]},{"cell_type":"markdown","source":["### Streamlit app"],"metadata":{"id":"qD4NuTgdc55e"}},{"cell_type":"code","source":["%%writefile app.py\n","# magic command from jupyter notebook, writes whatever content insdie the cell to the .py file\n","import streamlit as st\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import io #pyhton built-in module to deal with input/output Memory Streams\n","import time\n","from image_processing import getTextFromImage\n","html_temp = \"\"\"\n","            <div style=\"background-color:{};padding:1px\">\n","\n","            </div>\n","            \"\"\"\n","\n","textContent = None\n","#SIDEBAR\n","\n","with st.sidebar:\n","  st.title(\":smile: Text from Image\")\n","  st.markdown(html_temp.format(\"rgba(55, 53, 47, 0.16)\"),unsafe_allow_html=True)\n","  st.markdown(\"\"\"\n","    # How does it work?\n","    Simply upload your images and get the extracted the Text content.\n","    \"\"\")\n","  st.markdown(html_temp.format(\"rgba(55, 53, 47, 0.16)\"),unsafe_allow_html=True)\n","# #CAMERA UPLOAD --LATER\n","# img_file_buffer = st.camera_input(\"Take a picture\")\n","# #opening Image file for Image Processing tasks via OpenCV\n","# if img_file_buffer is not None:\n","#   bytes_data = img_file_buffer.getvalue()\n","#   cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8),cv2.IMREAD_COLOR)\n","#   #check image type\n","#   st.write(type(cv2_img))\n","\n","# FILE_UPLOAD\n","st.title(\"ðŸ“· Image Upload and Processing\")\n","img_file = st.file_uploader(\"Upload Image file\", accept_multiple_files=False)\n","print(img_file)\n","\n","cv2_img = None\n","if img_file is not None:\n","    file_details = {\"fileName\": img_file.name, \"FileType\": img_file.type, \"FileSize\": f\"{img_file.size/1024:.2f} KB\"}\n","    try:\n","        if img_file.type == \"image/heic\":\n","            from pillow_heif import register_heif_opener\n","            register_heif_opener()\n","            image = Image.open(img_file)\n","            image = image.convert('RGB')\n","            buf = io.BytesIO()\n","            image.save(buf, format='JPEG')\n","            jpeg_bytes = buf.getvalue()\n","        else:\n","            jpeg_bytes = img_file.read()\n","\n","        cv2_img = cv2.imdecode(np.frombuffer(jpeg_bytes, np.uint8), cv2.IMREAD_COLOR) #cv2_img is in np array format\n","        # st.write(type(cv2_img))\n","        # st.image(cv2_img, channels=\"BGR\", caption=\"Uploaded Image\")\n","        # st.write(\"Image shape: \", cv2_img.shape)\n","    except Exception as e:\n","        st.error(f\"An error occurred: {str(e)}\")\n","        st.warning(\"Please upload an image file\")\n","\n","\n","\n","st.markdown(\"\"\"\n","<style>\n",".big-gap {\n","    margin-bottom: 2em;\n","}\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","st.markdown('<p class=\"big-gap\"></p>', unsafe_allow_html=True)\n","\n","\n","#OUTPUTS::\n","# Custom CSS for the blinking effect\n","st.markdown(\"\"\"\n","<style>\n","@keyframes blink {\n","    0% { opacity: 0; }\n","    50% { opacity: 1; }\n","    100% { opacity: 0; }\n","}\n",".blinking {\n","    animation: blink 1.5s linear infinite;\n","}\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","# Function to create a blinking loading message\n","def blinking_loading_message(message):\n","    return f'<p class=\"blinking\">{message}</p>'\n","\n","if cv2_img is not None:\n","    col1, col2 = st.columns(2, gap=\"large\")\n","    with col1:\n","        st.subheader(\"Image Column\")\n","        image_placeholder = st.empty()\n","        loading_message = st.empty()\n","        loading_message.text(\"Loading image...\")\n","        time.sleep(1)  # Reduced sleep time\n","        image_placeholder.image(cv2_img)\n","        loading_message.empty()\n","\n","    try:\n","        textContent = getTextFromImage(cv2_img)\n","    except Exception as e:\n","        st.error(f\"An error occurred while extracting text: {str(e)}\")\n","else:\n","    st.info(\"Please upload an image to see the content\")\n","\n","# Column 2: Text content with blinking loading sign\n","if textContent is not None:\n","  with col2:\n","    st.subheader(\"Text Content Column\")\n","\n","    # Placeholder for text content\n","    text_placeholder = st.empty()\n","\n","    # Blinking loading message\n","    loading_message = st.markdown(blinking_loading_message(\"Loading text content...\"), unsafe_allow_html=True)\n","\n","    # # Simulate text content loading\n","    # time.sleep(3)  # Simulate longer delay for text content\n","\n","    text_placeholder.text(textContent)\n","    st.write(len(textContent))\n","    loading_message.empty()\n","else:\n","  with col2:\n","    st.write(\"No text\")\n","\n","\n","\n","\n"],"metadata":{"id":"oJ5oTv6ZY7S7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ngrok tunneling into Streamlit\n","Start pyngrok tunneling to access streamlit inside local network of google colab server"],"metadata":{"id":"9KufLHuJdCdb"}},{"cell_type":"markdown","source":["Step 1: Go to the ngrok and get the authorization token and store it as google colab secret key"],"metadata":{"id":"fbfyvlu-dL4N"}},{"cell_type":"code","source":["from pyngrok import ngrok"],"metadata":{"id":"tOYJIcjmTQOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","NGROK_T = userdata.get('NGROKT')\n","# print(NGROK_T)"],"metadata":{"id":"xoXPW1vodquL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ngrok authtoken $NGROK_T"],"metadata":{"id":"ksQWsUzIdtfd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nohup streamlit run app.py --server.port 8502 &"],"metadata":{"id":"mihnj7AadxA8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Start ngrok tunnel to expose the Streamlit server\n","ngrok_tunnel = ngrok.connect(addr='8502', proto='http', bind_tls=True)"],"metadata":{"id":"iz1BvRz9d-fr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tunnels = ngrok.get_tunnels()\n","print(tunnels)\n"],"metadata":{"id":"biAnyEaud2-G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print the URL of the ngrok tunnel\n","print(' * Tunnel URL:', ngrok_tunnel.public_url)"],"metadata":{"id":"F5yR5j8Pd_oi"},"execution_count":null,"outputs":[]}]}